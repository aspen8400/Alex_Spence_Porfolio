{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "pd.options.display.max_rows = 2000\n",
    "pd.options.display.max_columns = 50\n",
    "import numpy as np\n",
    "from scipy import sparse\n",
    "from sklearn.linear_model import LogisticRegression, LassoCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import average_precision_score, roc_auc_score\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(x_train_loc = r'\\wordcount_train.npz',\n",
    "              x_val_loc = r'\\wordcount_valid.npz',\n",
    "              up = False, folder_loc = 'data'):\n",
    "    '''\n",
    "    loads the data from the csv and npz files given the specified locations of the files\n",
    "    inputs: file locations\n",
    "    outputs: x_train, y_train, x_val, y_val\n",
    "    \n",
    "    '''\n",
    "    if up == True :\n",
    "        df_train = pd.read_csv(os.path.join(folder_loc, 'df_train_up.csv'), header=0, index_col=0)\n",
    "    else :\n",
    "        df_train = pd.read_csv(os.path.join(folder_loc, 'df_train.csv'), header=0, index_col=0)\n",
    "    \n",
    "    df_val = pd.read_csv(os.path.join(folder_loc, 'df_valid.csv'), header=0, index_col=0)\n",
    "        \n",
    "    #Training data\n",
    "    y_train = df_train['label']\n",
    "\n",
    "    x_train = sparse.load_npz(os.path.join(folder_loc, x_train_loc))\n",
    "    x_train = sparse.hstack((x_train, df_train.drop(columns=['label']).values))\n",
    "    \n",
    "    #Validation data\n",
    "    y_val = df_val['label']\n",
    "\n",
    "    x_val = sparse.load_npz(os.path.join(folder_loc, x_val_loc))\n",
    "    x_val = sparse.hstack((x_val, df_val.drop(columns=['label']).values))\n",
    "    \n",
    "    return x_train, y_train, x_val, y_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load various datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialze lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_ls = list()\n",
    "y_train_ls = list()\n",
    "x_val_ls = list()\n",
    "y_val_ls = list()\n",
    "params_ls = list()\n",
    "data_type_ls = list()\n",
    "\n",
    "def append_to_lists(x_train, y_train, x_val, y_val, params, data_type) :\n",
    "    x_train_ls.append(x_train)\n",
    "    y_train_ls.append(y_train)\n",
    "    x_val_ls.append(x_val)\n",
    "    y_val_ls.append(y_val)\n",
    "    params_ls.append(params)\n",
    "    data_type_ls.append(data_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standard Count data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_t, y_t, x_val, y_val = load_data(x_train_loc = 'wordcount_train.npz',\n",
    "              x_val_loc = 'wordcount_valid.npz', up = False)\n",
    "\n",
    "l1_params = np.logspace(start = math.log10(0.20), stop = math.log10(0.25), num = 5) #Creates evenly spaced intervals from base**start, base 10 default\n",
    "                   #first round had best val scores w/ l1 = 0.08 to 0.20\n",
    "                    # SEcond round had best val scores > 0.20\n",
    "\n",
    "append_to_lists(x_t, y_t, x_val, y_val, l1_params, 'count')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upsampled wordcount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_t, y_t, x_val, y_val = load_data(x_train_loc = 'wordcount_train_up.npz',\n",
    "              x_val_loc = 'wordcount_valid_up.npz', up = True)\n",
    "\n",
    "l1_params = np.logspace(start = math.log10(0.001), stop = math.log10(0.25), num = 10) #Creates evenly spaced intervals from base**start, base 10 default\n",
    "                   #first round had best val scores \n",
    "                    # Second round had best val scores \n",
    "\n",
    "append_to_lists(x_t, y_t, x_val, y_val, l1_params, 'count_up' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TFIDF norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_t, y_t, x_val, y_val = load_data(x_train_loc = 'tfidfnorm_train.npz',\n",
    "              x_val_loc = 'tfidfnorm_valid.npz', up = False)\n",
    "l1_params = np.logspace(start = math.log10(0.001), stop = math.log10(0.25), num = 10) #Creates evenly spaced intervals from base**start, base 10 default\n",
    "                   #first round had best val scores \n",
    "                    # SEcond round had best val scores \n",
    "        \n",
    "append_to_lists(x_t, y_t, x_val, y_val, l1_params, 'tfidf_norm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TFIDF norm trim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_t, y_t, x_val, y_val = load_data(x_train_loc = 'tfidfnorm_trim_train.npz',\n",
    "              x_val_loc = 'tfidfnorm_trim_valid.npz', up = False)\n",
    "l1_params = np.logspace(start = math.log10(0.001), stop = math.log10(0.25), num = 10) #Creates evenly spaced intervals from base**start, base 10 default\n",
    "                   #first round had best val scores \n",
    "                    # SEcond round had best val scores \n",
    "append_to_lists(x_t, y_t, x_val, y_val, l1_params, 'tfidf_norm_trim')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TFIDF norm trim up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_t, y_t, x_val, y_val = load_data(x_train_loc = 'tfidfnorm_trim_train_up.npz',\n",
    "              x_val_loc = 'tfidfnorm_trim_valid_up.npz', up = True)\n",
    "l1_params = np.logspace(start = math.log10(0.001), stop = math.log10(0.25), num = 10) #Creates evenly spaced intervals from base**start, base 10 default\n",
    "                   #first round had best val scores \n",
    "                    # SEcond round had best val scores \n",
    "append_to_lists(x_t, y_t, x_val, y_val, l1_params, 'tfidf_norm_trim_up')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TFIDF norm up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_t, y_t, x_val, y_val = load_data(x_train_loc = 'tfidfnorm_train_up.npz',\n",
    "              x_val_loc = 'tfidfnorm_valid_up.npz', up = True)\n",
    "l1_params = np.logspace(start = math.log10(0.001), stop = math.log10(0.25), num = 10) #Creates evenly spaced intervals from base**start, base 10 default\n",
    "                   #first round had best val scores \n",
    "                    # SEcond round had best val scores \n",
    "append_to_lists(x_t, y_t, x_val, y_val, l1_params, 'tfidf_norm_up')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## N-Gram Snow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data\\\\ngram_snow_train.npz'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-8b454564cfad>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m x_t, y_t, x_val, y_val = load_data(x_train_loc = 'ngram_snow_train.npz',\n\u001b[1;32m----> 2\u001b[1;33m               x_val_loc = r'ngram_snow_valid.npz', up = False)\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0ml1_params\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlogspace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog10\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.001\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstop\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog10\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.25\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#Creates evenly spaced intervals from base**start, base 10 default\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m                    \u001b[1;31m#first round had best val scores\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m                     \u001b[1;31m# SEcond round had best val scores\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-20-cfddda21dca4>\u001b[0m in \u001b[0;36mload_data\u001b[1;34m(x_train_loc, x_val_loc, up, folder_loc)\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[0my_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'label'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m     \u001b[0mx_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msparse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_npz\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfolder_loc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_train_loc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m     \u001b[0mx_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msparse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'label'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\scipy\\sparse\\_matrix_io.py\u001b[0m in \u001b[0;36mload_npz\u001b[1;34m(file)\u001b[0m\n\u001b[0;32m    129\u001b[0m     \"\"\"\n\u001b[0;32m    130\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m     \u001b[1;32mwith\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mPICKLE_KWARGS\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mloaded\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    132\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m             \u001b[0mmatrix_format\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloaded\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'format'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\numpy\\lib\\npyio.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[0;32m    382\u001b[0m     \u001b[0mown_fid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    383\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbasestring\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 384\u001b[1;33m         \u001b[0mfid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    385\u001b[0m         \u001b[0mown_fid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    386\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mis_pathlib_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data\\\\ngram_snow_train.npz'"
     ]
    }
   ],
   "source": [
    "x_t, y_t, x_val, y_val = load_data(x_train_loc = 'ngram_snow_train.npz',\n",
    "              x_val_loc = r'ngram_snow_valid.npz', up = False)\n",
    "l1_params = np.logspace(start = math.log10(0.001), stop = math.log10(0.25), num = 10) #Creates evenly spaced intervals from base**start, base 10 default\n",
    "                   #first round had best val scores \n",
    "                    # SEcond round had best val scores \n",
    "append_to_lists(x_t, y_t, x_val, y_val, l1_params, 'ngram_snow')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## N-Gram Snow TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_t, y_t, x_val, y_val = load_data(x_train_loc = 'ngram_snow_tfidf_train.npz',\n",
    "              x_val_loc = 'ngram_snow_tfidf_valid.npz', up = False)\n",
    "l1_params = np.logspace(start = math.log10(0.001), stop = math.log10(0.25), num = 10) #Creates evenly spaced intervals from base**start, base 10 default\n",
    "                   #first round had best val scores \n",
    "                    # SEcond round had best val scores \n",
    "append_to_lists(x_t, y_t, x_val, y_val, l1_params, 'ngram_snow_tfidf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def l1_reg(x_train, y_train, x_val, y_val, l1_params, data_type) : # x_val, y_val\n",
    "    '''\n",
    "    inputs:\n",
    "    x_train: training data features\n",
    "    y_train: training data classifications 0 or 1\n",
    "    x_val: validation data features\n",
    "    y_val: validation data classifications 0 or 1\n",
    "    l1_params: list of params to test\n",
    "    \n",
    "    returns \n",
    "    df: l1_param, roc_auc_train, ap_train, roc_auc_val, ap_val, dataset_type'''\n",
    "    \n",
    "    print(data_type)\n",
    "    df = pd.DataFrame(columns = ['l1_param', 'roc_auc_train', 'ap_train', 'roc_auc_val','ap_val', 'data_type'])\n",
    "    for l1 in l1_params : #iterate thru each parameter\n",
    "        print('l1: {}'.format(l1))\n",
    "        clf = LogisticRegression(penalty = 'l1', C = l1, solver = 'liblinear') #Generate LR l1 object\n",
    "        clf.fit(X = x_train, y = y_train) #Fit object to training data\n",
    "        y_train_pred = clf.predict_proba(X = x_train) #predict training values\n",
    "        y_val_pred = clf.predict_proba(X= x_val) #predict validation values\n",
    "        \n",
    "        ap_train = average_precision_score(y_train, y_train_pred[:,1])\n",
    "        roc_auc_train = roc_auc_score(y_train, y_train_pred[:, 1])\n",
    "        \n",
    "        ap_val = average_precision_score(y_val, y_val_pred[:, 1])\n",
    "        roc_auc_val = roc_auc_score(y_val, y_val_pred[:, 1])\n",
    "        \n",
    "        print('ap_train: {}, roc_train: {}, ap_val: {}, roc_val: {}'.format(ap_train, roc_auc_train, ap_val, roc_auc_val))\n",
    "        \n",
    "        df = df.append({'l1_param': round(l1,3), 'roc_auc_train': round(roc_auc_train,3),\\\n",
    "                           'ap_train': round(ap_train,3), 'roc_auc_val': round(roc_auc_val, 3),\\\n",
    "                        'ap_val' : round(ap_val,3), 'data_type': data_type}, True)\n",
    "#     print('\\n')\n",
    "    return df\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize results dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df = pd.DataFrame(columns = ['l1_param', 'roc_auc_train', 'ap_train', 'roc_auc_val', 'ap_val', 'data_type'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model each scenario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count\n",
      "l1: 0.20000000000000004\n",
      "ap_train: 0.3261658737905971, roc_train: 0.8133221328774791, ap_val: 0.23130077016912742, roc_val: 0.7479483475160243\n",
      "l1: 0.21147425268811282\n",
      "ap_train: 0.32875620108408876, roc_train: 0.8143972109794311, ap_val: 0.23107500842392215, roc_val: 0.7477620425453548\n",
      "l1: 0.22360679774997896\n",
      "ap_train: 0.3314262133261266, roc_train: 0.8154771236149083, ap_val: 0.230650381596736, roc_val: 0.74747858410261\n",
      "l1: 0.23643540225079399\n",
      "ap_train: 0.3342694217200821, roc_train: 0.8165427352933818, ap_val: 0.22979650815695163, roc_val: 0.7469248084623163\n",
      "l1: 0.25\n",
      "ap_train: 0.33724484832101254, roc_train: 0.8177749415861834, ap_val: 0.22960018477485652, roc_val: 0.7468120587871523\n",
      "count_up\n",
      "l1: 0.001\n",
      "ap_train: 0.984368067091562, roc_train: 0.9820383485473076, ap_val: 0.17994477997626557, roc_val: 0.7043094916996939\n",
      "l1: 0.0018468761744797571\n",
      "ap_train: 0.9848780438144948, roc_train: 0.9826602850251509, ap_val: 0.18588236509431927, roc_val: 0.7141141433097385\n",
      "l1: 0.0034109516038609822\n",
      "ap_train: 0.9852940790385228, roc_train: 0.983197366222498, ap_val: 0.19218206254801903, roc_val: 0.7208092127349284\n",
      "l1: 0.00629960524947437\n",
      "ap_train: 0.9858808581157124, roc_train: 0.9840459652665798, ap_val: 0.19766287061723423, roc_val: 0.7257436186385161\n",
      "l1: 0.011634590843881814\n",
      "ap_train: 0.9866739930260395, roc_train: 0.9851990609977902, ap_val: 0.1999930521195723, roc_val: 0.7275081982002186\n",
      "l1: 0.021487648629385653\n",
      "ap_train: 0.987552722344329, roc_train: 0.9864580974824999, ap_val: 0.19817350883332002, roc_val: 0.7249074209044846\n",
      "l1: 0.03968502629920499\n",
      "ap_train: 0.9888407537642827, roc_train: 0.9882912914460357, ap_val: 0.19587846745899362, roc_val: 0.7212499923548025\n",
      "l1: 0.07329332955560428\n",
      "ap_train: 0.9904286569103897, roc_train: 0.990388644535745, ap_val: 0.1928153815308028, roc_val: 0.7160596677091319\n",
      "l1: 0.13536370410453855\n",
      "ap_train: 0.9923213566700471, roc_train: 0.9926740439915501, ap_val: 0.18940123952286772, roc_val: 0.709975432582269\n",
      "l1: 0.25\n",
      "ap_train: 0.9943251781711769, roc_train: 0.9948954134510313, ap_val: 0.1860264039845445, roc_val: 0.7040543629613621\n",
      "tfidf_norm\n",
      "l1: 0.001\n",
      "ap_train: 0.21945213229898988, roc_train: 0.755098865027428, ap_val: 0.1808384597193801, roc_val: 0.692122537057122\n",
      "l1: 0.0018468761744797571\n",
      "ap_train: 0.2183866205236859, roc_train: 0.7552563730351469, ap_val: 0.18021272807987623, roc_val: 0.6918079371761834\n",
      "l1: 0.0034109516038609822\n",
      "ap_train: 0.21836386200555696, roc_train: 0.7553080640975196, ap_val: 0.18021058709323334, roc_val: 0.6912387607100724\n",
      "l1: 0.00629960524947437\n",
      "ap_train: 0.22334025582410819, roc_train: 0.7581044273336152, ap_val: 0.18424964643590952, roc_val: 0.6938583112132284\n",
      "l1: 0.011634590843881814\n",
      "ap_train: 0.23173208823389557, roc_train: 0.7627167449294354, ap_val: 0.19150823357941257, roc_val: 0.6997969902725905\n",
      "l1: 0.021487648629385653\n",
      "ap_train: 0.2456756958601993, roc_train: 0.7710847781205492, ap_val: 0.20773640216702205, roc_val: 0.7148049378802213\n",
      "l1: 0.03968502629920499\n",
      "ap_train: 0.2586041227883276, roc_train: 0.7784833987101797, ap_val: 0.21903994004587157, roc_val: 0.728307732964461\n",
      "l1: 0.07329332955560428\n",
      "ap_train: 0.26960722403712045, roc_train: 0.7843912137364627, ap_val: 0.22716000294137556, roc_val: 0.7385307127974492\n",
      "l1: 0.13536370410453855\n",
      "ap_train: 0.2796642301704527, roc_train: 0.7895196174419097, ap_val: 0.2340765423227749, roc_val: 0.7452602280851262\n",
      "l1: 0.25\n",
      "ap_train: 0.29138181717007117, roc_train: 0.7953893922684769, ap_val: 0.24115210119430444, roc_val: 0.7515000769616559\n",
      "tfidf_norm_trim\n",
      "l1: 0.001\n",
      "ap_train: 0.21925259134712216, roc_train: 0.7550866867941097, ap_val: 0.18071695380126182, roc_val: 0.6922211855900597\n",
      "l1: 0.0018468761744797571\n",
      "ap_train: 0.2186863415119352, roc_train: 0.755266860076633, ap_val: 0.18032279967925355, roc_val: 0.6916252594270382\n",
      "l1: 0.0034109516038609822\n",
      "ap_train: 0.21844857173920615, roc_train: 0.755304245621446, ap_val: 0.18023612659380742, roc_val: 0.6911771998801233\n",
      "l1: 0.00629960524947437\n",
      "ap_train: 0.22301342467812876, roc_train: 0.7578486424423947, ap_val: 0.1835757160625173, roc_val: 0.6932150952557641\n",
      "l1: 0.011634590843881814\n",
      "ap_train: 0.2318280935707155, roc_train: 0.7626969656260802, ap_val: 0.1925335107106657, roc_val: 0.7005165732593415\n",
      "l1: 0.021487648629385653\n",
      "ap_train: 0.2461174772707469, roc_train: 0.7709431305218325, ap_val: 0.20807412428617716, roc_val: 0.7148095589774327\n",
      "l1: 0.03968502629920499\n",
      "ap_train: 0.2564620927002781, roc_train: 0.7769043914780078, ap_val: 0.2169195919085436, roc_val: 0.725456456522271\n",
      "l1: 0.07329332955560428\n",
      "ap_train: 0.26718340825763004, roc_train: 0.7827644411340812, ap_val: 0.22544025017036035, roc_val: 0.7358472994104023\n",
      "l1: 0.13536370410453855\n",
      "ap_train: 0.2772875132478824, roc_train: 0.7880836437011813, ap_val: 0.23276255169825327, roc_val: 0.743358323785331\n",
      "l1: 0.25\n",
      "ap_train: 0.289407478405207, roc_train: 0.7942516011868939, ap_val: 0.2393262586670783, roc_val: 0.7493293335358461\n",
      "tfidf_norm_trim_up\n",
      "l1: 0.001\n",
      "ap_train: 0.9834712497578555, roc_train: 0.9808277752702823, ap_val: 0.16599191412302006, roc_val: 0.6808593006716901\n",
      "l1: 0.0018468761744797571\n",
      "ap_train: 0.983506178070487, roc_train: 0.980833710481849, ap_val: 0.16536346837159985, roc_val: 0.6810046868459109\n",
      "l1: 0.0034109516038609822\n",
      "ap_train: 0.9835042211671313, roc_train: 0.9808067961156657, ap_val: 0.16502645887356585, roc_val: 0.6806483356914521\n",
      "l1: 0.00629960524947437\n",
      "ap_train: 0.9836786361022378, roc_train: 0.9810431166460756, ap_val: 0.17013754713701001, roc_val: 0.6865619172660502\n",
      "l1: 0.011634590843881814\n",
      "ap_train: 0.9839822308891162, roc_train: 0.9814676584002949, ap_val: 0.17758383323113955, roc_val: 0.6962271586979922\n",
      "l1: 0.021487648629385653\n",
      "ap_train: 0.9843953813144377, roc_train: 0.9820388348872902, ap_val: 0.186589437891204, roc_val: 0.7082151428258825\n",
      "l1: 0.03968502629920499\n",
      "ap_train: 0.9848551571330468, roc_train: 0.9826719256051101, ap_val: 0.19467297934689376, roc_val: 0.718182849511251\n",
      "l1: 0.07329332955560428\n",
      "ap_train: 0.9855184561732142, roc_train: 0.983568679582915, ap_val: 0.20295796736180605, roc_val: 0.7267450460818532\n",
      "l1: 0.13536370410453855\n",
      "ap_train: 0.9865075972463069, roc_train: 0.9849072793677262, ap_val: 0.20689216858119086, roc_val: 0.7285642633223514\n",
      "l1: 0.25\n",
      "ap_train: 0.9882393108928086, roc_train: 0.9872165446161127, ap_val: 0.2055039413516517, roc_val: 0.724497519388221\n",
      "tfidf_norm_up\n",
      "l1: 0.001\n",
      "ap_train: 0.9834707306074356, roc_train: 0.9808274304314832, ap_val: 0.1659535129812621, roc_val: 0.6808548834464142\n",
      "l1: 0.0018468761744797571\n",
      "ap_train: 0.9835061117839423, roc_train: 0.9808337536311214, ap_val: 0.16536398265673738, roc_val: 0.6810068190065728\n",
      "l1: 0.0034109516038609822\n",
      "ap_train: 0.9835043157612979, roc_train: 0.9808071552684535, ap_val: 0.16502669469931996, roc_val: 0.6806512323718733\n",
      "l1: 0.00629960524947437\n",
      "ap_train: 0.9837313286244685, roc_train: 0.9811066476172615, ap_val: 0.17006789213085066, roc_val: 0.6864048296921806\n",
      "l1: 0.011634590843881814\n",
      "ap_train: 0.9839623745827887, roc_train: 0.9814193663385588, ap_val: 0.17606361575968205, roc_val: 0.6941706727502053\n",
      "l1: 0.021487648629385653\n",
      "ap_train: 0.9844801166975432, roc_train: 0.9821443584620521, ap_val: 0.18641901417429713, roc_val: 0.7092270781685777\n",
      "l1: 0.03968502629920499\n",
      "ap_train: 0.984972384268151, roc_train: 0.9828268698255909, ap_val: 0.19519093685261646, roc_val: 0.7199510223158221\n",
      "l1: 0.07329332955560428\n",
      "ap_train: 0.9856296841032541, roc_train: 0.9837000778544269, ap_val: 0.20361015523432424, roc_val: 0.7281173675444033\n",
      "l1: 0.13536370410453855\n",
      "ap_train: 0.986541938556198, roc_train: 0.9849163794120988, ap_val: 0.20763919055924096, roc_val: 0.7300355391257428\n",
      "l1: 0.25\n",
      "ap_train: 0.9881582360770792, roc_train: 0.9870679801207185, ap_val: 0.2061878833250642, roc_val: 0.7257209803589776\n",
      "ngram_snow_tfidf\n",
      "l1: 0.001\n",
      "ap_train: 0.21924555888960437, roc_train: 0.7550855592181572, ap_val: 0.18071485708318397, roc_val: 0.6922243371104007\n",
      "l1: 0.0018468761744797571\n",
      "ap_train: 0.21875309254235692, roc_train: 0.7552626474996849, ap_val: 0.1803443055340105, roc_val: 0.6915770097355645\n",
      "l1: 0.0034109516038609822\n",
      "ap_train: 0.21846186464342113, roc_train: 0.7553000941387383, ap_val: 0.18023324621346548, roc_val: 0.6911511212616683\n",
      "l1: 0.00629960524947437\n",
      "ap_train: 0.2188824126221381, roc_train: 0.7557526131540431, ap_val: 0.18001442088729058, roc_val: 0.6910922999608565\n",
      "l1: 0.011634590843881814\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ap_train: 0.21941666105174296, roc_train: 0.7560822294882625, ap_val: 0.18006078317839316, roc_val: 0.6911386850735842\n",
      "l1: 0.021487648629385653\n",
      "ap_train: 0.22578842487327702, roc_train: 0.7593956233853604, ap_val: 0.18643124467868954, roc_val: 0.6958355631826313\n",
      "l1: 0.03968502629920499\n",
      "ap_train: 0.23369253270594326, roc_train: 0.763949103183404, ap_val: 0.19469472284101702, roc_val: 0.7030454899450361\n",
      "l1: 0.07329332955560428\n",
      "ap_train: 0.24797660426917195, roc_train: 0.7727397291936184, ap_val: 0.21073115300049763, roc_val: 0.7194919324477136\n",
      "l1: 0.13536370410453855\n",
      "ap_train: 0.26141030573193963, roc_train: 0.7803265603142662, ap_val: 0.22211048376478415, roc_val: 0.7328619601810926\n",
      "l1: 0.25\n",
      "ap_train: 0.27442491171449734, roc_train: 0.7869235474566193, ap_val: 0.23278428068054352, roc_val: 0.7435375527008954\n"
     ]
    }
   ],
   "source": [
    "for x_t, y_t, x_val, y_val, param, data_type in zip(x_train_ls, y_train_ls, x_val_ls, y_val_ls, params_ls, data_type_ls) :\n",
    "    l1_results_df = l1_reg(x_t, y_t, x_val, y_val, param, data_type)\n",
    "    master_df = pd.concat([master_df, l1_results_df], ignore_index = True, sort = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data_type</th>\n",
       "      <th>l1_param</th>\n",
       "      <th>ap_train</th>\n",
       "      <th>roc_auc_train</th>\n",
       "      <th>ap_val</th>\n",
       "      <th>roc_auc_val</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>count</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.326</td>\n",
       "      <td>0.813</td>\n",
       "      <td>0.231</td>\n",
       "      <td>0.748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>count</td>\n",
       "      <td>0.211</td>\n",
       "      <td>0.329</td>\n",
       "      <td>0.814</td>\n",
       "      <td>0.231</td>\n",
       "      <td>0.748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>count</td>\n",
       "      <td>0.224</td>\n",
       "      <td>0.331</td>\n",
       "      <td>0.815</td>\n",
       "      <td>0.231</td>\n",
       "      <td>0.747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>count</td>\n",
       "      <td>0.236</td>\n",
       "      <td>0.334</td>\n",
       "      <td>0.817</td>\n",
       "      <td>0.230</td>\n",
       "      <td>0.747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>count</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.337</td>\n",
       "      <td>0.818</td>\n",
       "      <td>0.230</td>\n",
       "      <td>0.747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>count_up</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.984</td>\n",
       "      <td>0.982</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>count_up</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.985</td>\n",
       "      <td>0.983</td>\n",
       "      <td>0.186</td>\n",
       "      <td>0.714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>count_up</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.985</td>\n",
       "      <td>0.983</td>\n",
       "      <td>0.192</td>\n",
       "      <td>0.721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>count_up</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.986</td>\n",
       "      <td>0.984</td>\n",
       "      <td>0.198</td>\n",
       "      <td>0.726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>count_up</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.987</td>\n",
       "      <td>0.985</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>count_up</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.988</td>\n",
       "      <td>0.986</td>\n",
       "      <td>0.198</td>\n",
       "      <td>0.725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>count_up</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.989</td>\n",
       "      <td>0.988</td>\n",
       "      <td>0.196</td>\n",
       "      <td>0.721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>count_up</td>\n",
       "      <td>0.073</td>\n",
       "      <td>0.990</td>\n",
       "      <td>0.990</td>\n",
       "      <td>0.193</td>\n",
       "      <td>0.716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>count_up</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.992</td>\n",
       "      <td>0.993</td>\n",
       "      <td>0.189</td>\n",
       "      <td>0.710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>count_up</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.994</td>\n",
       "      <td>0.995</td>\n",
       "      <td>0.186</td>\n",
       "      <td>0.704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>tfidf_norm</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.219</td>\n",
       "      <td>0.755</td>\n",
       "      <td>0.181</td>\n",
       "      <td>0.692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>tfidf_norm</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.218</td>\n",
       "      <td>0.755</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>tfidf_norm</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.218</td>\n",
       "      <td>0.755</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>tfidf_norm</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.223</td>\n",
       "      <td>0.758</td>\n",
       "      <td>0.184</td>\n",
       "      <td>0.694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>tfidf_norm</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.232</td>\n",
       "      <td>0.763</td>\n",
       "      <td>0.192</td>\n",
       "      <td>0.700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>tfidf_norm</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.246</td>\n",
       "      <td>0.771</td>\n",
       "      <td>0.208</td>\n",
       "      <td>0.715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>tfidf_norm</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.259</td>\n",
       "      <td>0.778</td>\n",
       "      <td>0.219</td>\n",
       "      <td>0.728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>tfidf_norm</td>\n",
       "      <td>0.073</td>\n",
       "      <td>0.270</td>\n",
       "      <td>0.784</td>\n",
       "      <td>0.227</td>\n",
       "      <td>0.739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>tfidf_norm</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.280</td>\n",
       "      <td>0.790</td>\n",
       "      <td>0.234</td>\n",
       "      <td>0.745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>tfidf_norm</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.291</td>\n",
       "      <td>0.795</td>\n",
       "      <td>0.241</td>\n",
       "      <td>0.752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>tfidf_norm_trim</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.219</td>\n",
       "      <td>0.755</td>\n",
       "      <td>0.181</td>\n",
       "      <td>0.692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>tfidf_norm_trim</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.219</td>\n",
       "      <td>0.755</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>tfidf_norm_trim</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.218</td>\n",
       "      <td>0.755</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>tfidf_norm_trim</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.223</td>\n",
       "      <td>0.758</td>\n",
       "      <td>0.184</td>\n",
       "      <td>0.693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>tfidf_norm_trim</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.232</td>\n",
       "      <td>0.763</td>\n",
       "      <td>0.193</td>\n",
       "      <td>0.701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>tfidf_norm_trim</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.246</td>\n",
       "      <td>0.771</td>\n",
       "      <td>0.208</td>\n",
       "      <td>0.715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>tfidf_norm_trim</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.256</td>\n",
       "      <td>0.777</td>\n",
       "      <td>0.217</td>\n",
       "      <td>0.725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>tfidf_norm_trim</td>\n",
       "      <td>0.073</td>\n",
       "      <td>0.267</td>\n",
       "      <td>0.783</td>\n",
       "      <td>0.225</td>\n",
       "      <td>0.736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>tfidf_norm_trim</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.277</td>\n",
       "      <td>0.788</td>\n",
       "      <td>0.233</td>\n",
       "      <td>0.743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>tfidf_norm_trim</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.289</td>\n",
       "      <td>0.794</td>\n",
       "      <td>0.239</td>\n",
       "      <td>0.749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>tfidf_norm_trim_up</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.983</td>\n",
       "      <td>0.981</td>\n",
       "      <td>0.166</td>\n",
       "      <td>0.681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>tfidf_norm_trim_up</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.984</td>\n",
       "      <td>0.981</td>\n",
       "      <td>0.165</td>\n",
       "      <td>0.681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>tfidf_norm_trim_up</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.984</td>\n",
       "      <td>0.981</td>\n",
       "      <td>0.165</td>\n",
       "      <td>0.681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>tfidf_norm_trim_up</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.984</td>\n",
       "      <td>0.981</td>\n",
       "      <td>0.170</td>\n",
       "      <td>0.687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>tfidf_norm_trim_up</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.984</td>\n",
       "      <td>0.981</td>\n",
       "      <td>0.178</td>\n",
       "      <td>0.696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>tfidf_norm_trim_up</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.984</td>\n",
       "      <td>0.982</td>\n",
       "      <td>0.187</td>\n",
       "      <td>0.708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>tfidf_norm_trim_up</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.985</td>\n",
       "      <td>0.983</td>\n",
       "      <td>0.195</td>\n",
       "      <td>0.718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>tfidf_norm_trim_up</td>\n",
       "      <td>0.073</td>\n",
       "      <td>0.986</td>\n",
       "      <td>0.984</td>\n",
       "      <td>0.203</td>\n",
       "      <td>0.727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>tfidf_norm_trim_up</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.987</td>\n",
       "      <td>0.985</td>\n",
       "      <td>0.207</td>\n",
       "      <td>0.729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>tfidf_norm_trim_up</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.988</td>\n",
       "      <td>0.987</td>\n",
       "      <td>0.206</td>\n",
       "      <td>0.724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>tfidf_norm_up</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.983</td>\n",
       "      <td>0.981</td>\n",
       "      <td>0.166</td>\n",
       "      <td>0.681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>tfidf_norm_up</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.984</td>\n",
       "      <td>0.981</td>\n",
       "      <td>0.165</td>\n",
       "      <td>0.681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>tfidf_norm_up</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.984</td>\n",
       "      <td>0.981</td>\n",
       "      <td>0.165</td>\n",
       "      <td>0.681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>tfidf_norm_up</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.984</td>\n",
       "      <td>0.981</td>\n",
       "      <td>0.170</td>\n",
       "      <td>0.686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>tfidf_norm_up</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.984</td>\n",
       "      <td>0.981</td>\n",
       "      <td>0.176</td>\n",
       "      <td>0.694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>tfidf_norm_up</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.984</td>\n",
       "      <td>0.982</td>\n",
       "      <td>0.186</td>\n",
       "      <td>0.709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>tfidf_norm_up</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.985</td>\n",
       "      <td>0.983</td>\n",
       "      <td>0.195</td>\n",
       "      <td>0.720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>tfidf_norm_up</td>\n",
       "      <td>0.073</td>\n",
       "      <td>0.986</td>\n",
       "      <td>0.984</td>\n",
       "      <td>0.204</td>\n",
       "      <td>0.728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>tfidf_norm_up</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.987</td>\n",
       "      <td>0.985</td>\n",
       "      <td>0.208</td>\n",
       "      <td>0.730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>tfidf_norm_up</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.988</td>\n",
       "      <td>0.987</td>\n",
       "      <td>0.206</td>\n",
       "      <td>0.726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>ngram_snow_tfidf</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.219</td>\n",
       "      <td>0.755</td>\n",
       "      <td>0.181</td>\n",
       "      <td>0.692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>ngram_snow_tfidf</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.219</td>\n",
       "      <td>0.755</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>ngram_snow_tfidf</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.218</td>\n",
       "      <td>0.755</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>ngram_snow_tfidf</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.219</td>\n",
       "      <td>0.756</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>ngram_snow_tfidf</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.219</td>\n",
       "      <td>0.756</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>ngram_snow_tfidf</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.226</td>\n",
       "      <td>0.759</td>\n",
       "      <td>0.186</td>\n",
       "      <td>0.696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>ngram_snow_tfidf</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.234</td>\n",
       "      <td>0.764</td>\n",
       "      <td>0.195</td>\n",
       "      <td>0.703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>ngram_snow_tfidf</td>\n",
       "      <td>0.073</td>\n",
       "      <td>0.248</td>\n",
       "      <td>0.773</td>\n",
       "      <td>0.211</td>\n",
       "      <td>0.719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>ngram_snow_tfidf</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.261</td>\n",
       "      <td>0.780</td>\n",
       "      <td>0.222</td>\n",
       "      <td>0.733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>ngram_snow_tfidf</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.274</td>\n",
       "      <td>0.787</td>\n",
       "      <td>0.233</td>\n",
       "      <td>0.744</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             data_type  l1_param  ap_train  roc_auc_train  ap_val  roc_auc_val\n",
       "0                count     0.200     0.326          0.813   0.231        0.748\n",
       "1                count     0.211     0.329          0.814   0.231        0.748\n",
       "2                count     0.224     0.331          0.815   0.231        0.747\n",
       "3                count     0.236     0.334          0.817   0.230        0.747\n",
       "4                count     0.250     0.337          0.818   0.230        0.747\n",
       "5             count_up     0.001     0.984          0.982   0.180        0.704\n",
       "6             count_up     0.002     0.985          0.983   0.186        0.714\n",
       "7             count_up     0.003     0.985          0.983   0.192        0.721\n",
       "8             count_up     0.006     0.986          0.984   0.198        0.726\n",
       "9             count_up     0.012     0.987          0.985   0.200        0.728\n",
       "10            count_up     0.021     0.988          0.986   0.198        0.725\n",
       "11            count_up     0.040     0.989          0.988   0.196        0.721\n",
       "12            count_up     0.073     0.990          0.990   0.193        0.716\n",
       "13            count_up     0.135     0.992          0.993   0.189        0.710\n",
       "14            count_up     0.250     0.994          0.995   0.186        0.704\n",
       "15          tfidf_norm     0.001     0.219          0.755   0.181        0.692\n",
       "16          tfidf_norm     0.002     0.218          0.755   0.180        0.692\n",
       "17          tfidf_norm     0.003     0.218          0.755   0.180        0.691\n",
       "18          tfidf_norm     0.006     0.223          0.758   0.184        0.694\n",
       "19          tfidf_norm     0.012     0.232          0.763   0.192        0.700\n",
       "20          tfidf_norm     0.021     0.246          0.771   0.208        0.715\n",
       "21          tfidf_norm     0.040     0.259          0.778   0.219        0.728\n",
       "22          tfidf_norm     0.073     0.270          0.784   0.227        0.739\n",
       "23          tfidf_norm     0.135     0.280          0.790   0.234        0.745\n",
       "24          tfidf_norm     0.250     0.291          0.795   0.241        0.752\n",
       "25     tfidf_norm_trim     0.001     0.219          0.755   0.181        0.692\n",
       "26     tfidf_norm_trim     0.002     0.219          0.755   0.180        0.692\n",
       "27     tfidf_norm_trim     0.003     0.218          0.755   0.180        0.691\n",
       "28     tfidf_norm_trim     0.006     0.223          0.758   0.184        0.693\n",
       "29     tfidf_norm_trim     0.012     0.232          0.763   0.193        0.701\n",
       "30     tfidf_norm_trim     0.021     0.246          0.771   0.208        0.715\n",
       "31     tfidf_norm_trim     0.040     0.256          0.777   0.217        0.725\n",
       "32     tfidf_norm_trim     0.073     0.267          0.783   0.225        0.736\n",
       "33     tfidf_norm_trim     0.135     0.277          0.788   0.233        0.743\n",
       "34     tfidf_norm_trim     0.250     0.289          0.794   0.239        0.749\n",
       "35  tfidf_norm_trim_up     0.001     0.983          0.981   0.166        0.681\n",
       "36  tfidf_norm_trim_up     0.002     0.984          0.981   0.165        0.681\n",
       "37  tfidf_norm_trim_up     0.003     0.984          0.981   0.165        0.681\n",
       "38  tfidf_norm_trim_up     0.006     0.984          0.981   0.170        0.687\n",
       "39  tfidf_norm_trim_up     0.012     0.984          0.981   0.178        0.696\n",
       "40  tfidf_norm_trim_up     0.021     0.984          0.982   0.187        0.708\n",
       "41  tfidf_norm_trim_up     0.040     0.985          0.983   0.195        0.718\n",
       "42  tfidf_norm_trim_up     0.073     0.986          0.984   0.203        0.727\n",
       "43  tfidf_norm_trim_up     0.135     0.987          0.985   0.207        0.729\n",
       "44  tfidf_norm_trim_up     0.250     0.988          0.987   0.206        0.724\n",
       "45       tfidf_norm_up     0.001     0.983          0.981   0.166        0.681\n",
       "46       tfidf_norm_up     0.002     0.984          0.981   0.165        0.681\n",
       "47       tfidf_norm_up     0.003     0.984          0.981   0.165        0.681\n",
       "48       tfidf_norm_up     0.006     0.984          0.981   0.170        0.686\n",
       "49       tfidf_norm_up     0.012     0.984          0.981   0.176        0.694\n",
       "50       tfidf_norm_up     0.021     0.984          0.982   0.186        0.709\n",
       "51       tfidf_norm_up     0.040     0.985          0.983   0.195        0.720\n",
       "52       tfidf_norm_up     0.073     0.986          0.984   0.204        0.728\n",
       "53       tfidf_norm_up     0.135     0.987          0.985   0.208        0.730\n",
       "54       tfidf_norm_up     0.250     0.988          0.987   0.206        0.726\n",
       "55    ngram_snow_tfidf     0.001     0.219          0.755   0.181        0.692\n",
       "56    ngram_snow_tfidf     0.002     0.219          0.755   0.180        0.692\n",
       "57    ngram_snow_tfidf     0.003     0.218          0.755   0.180        0.691\n",
       "58    ngram_snow_tfidf     0.006     0.219          0.756   0.180        0.691\n",
       "59    ngram_snow_tfidf     0.012     0.219          0.756   0.180        0.691\n",
       "60    ngram_snow_tfidf     0.021     0.226          0.759   0.186        0.696\n",
       "61    ngram_snow_tfidf     0.040     0.234          0.764   0.195        0.703\n",
       "62    ngram_snow_tfidf     0.073     0.248          0.773   0.211        0.719\n",
       "63    ngram_snow_tfidf     0.135     0.261          0.780   0.222        0.733\n",
       "64    ngram_snow_tfidf     0.250     0.274          0.787   0.233        0.744"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "final_cols = ['data_type', 'l1_param', 'ap_train', 'roc_auc_train', 'ap_val', 'roc_auc_val']\n",
    "master_df = master_df[final_cols]\n",
    "display(master_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df.to_csv(os.path.join('data', 'Logistic L1 Results.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data_type</th>\n",
       "      <th>l1_param</th>\n",
       "      <th>ap_train</th>\n",
       "      <th>roc_auc_train</th>\n",
       "      <th>ap_val</th>\n",
       "      <th>roc_auc_val</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>tfidf_norm</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.291</td>\n",
       "      <td>0.795</td>\n",
       "      <td>0.241</td>\n",
       "      <td>0.752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>tfidf_norm_trim</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.289</td>\n",
       "      <td>0.794</td>\n",
       "      <td>0.239</td>\n",
       "      <td>0.749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>tfidf_norm</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.280</td>\n",
       "      <td>0.790</td>\n",
       "      <td>0.234</td>\n",
       "      <td>0.745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>ngram_snow_tfidf</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.274</td>\n",
       "      <td>0.787</td>\n",
       "      <td>0.233</td>\n",
       "      <td>0.744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>tfidf_norm_trim</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.277</td>\n",
       "      <td>0.788</td>\n",
       "      <td>0.233</td>\n",
       "      <td>0.743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>count</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.326</td>\n",
       "      <td>0.813</td>\n",
       "      <td>0.231</td>\n",
       "      <td>0.748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>count</td>\n",
       "      <td>0.211</td>\n",
       "      <td>0.329</td>\n",
       "      <td>0.814</td>\n",
       "      <td>0.231</td>\n",
       "      <td>0.748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>count</td>\n",
       "      <td>0.224</td>\n",
       "      <td>0.331</td>\n",
       "      <td>0.815</td>\n",
       "      <td>0.231</td>\n",
       "      <td>0.747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>count</td>\n",
       "      <td>0.236</td>\n",
       "      <td>0.334</td>\n",
       "      <td>0.817</td>\n",
       "      <td>0.230</td>\n",
       "      <td>0.747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>count</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.337</td>\n",
       "      <td>0.818</td>\n",
       "      <td>0.230</td>\n",
       "      <td>0.747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>tfidf_norm</td>\n",
       "      <td>0.073</td>\n",
       "      <td>0.270</td>\n",
       "      <td>0.784</td>\n",
       "      <td>0.227</td>\n",
       "      <td>0.739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>tfidf_norm_trim</td>\n",
       "      <td>0.073</td>\n",
       "      <td>0.267</td>\n",
       "      <td>0.783</td>\n",
       "      <td>0.225</td>\n",
       "      <td>0.736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>ngram_snow_tfidf</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.261</td>\n",
       "      <td>0.780</td>\n",
       "      <td>0.222</td>\n",
       "      <td>0.733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>tfidf_norm</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.259</td>\n",
       "      <td>0.778</td>\n",
       "      <td>0.219</td>\n",
       "      <td>0.728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>tfidf_norm_trim</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.256</td>\n",
       "      <td>0.777</td>\n",
       "      <td>0.217</td>\n",
       "      <td>0.725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>ngram_snow_tfidf</td>\n",
       "      <td>0.073</td>\n",
       "      <td>0.248</td>\n",
       "      <td>0.773</td>\n",
       "      <td>0.211</td>\n",
       "      <td>0.719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>tfidf_norm_up</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.987</td>\n",
       "      <td>0.985</td>\n",
       "      <td>0.208</td>\n",
       "      <td>0.730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>tfidf_norm</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.246</td>\n",
       "      <td>0.771</td>\n",
       "      <td>0.208</td>\n",
       "      <td>0.715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>tfidf_norm_trim</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.246</td>\n",
       "      <td>0.771</td>\n",
       "      <td>0.208</td>\n",
       "      <td>0.715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>tfidf_norm_trim_up</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.987</td>\n",
       "      <td>0.985</td>\n",
       "      <td>0.207</td>\n",
       "      <td>0.729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>tfidf_norm_up</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.988</td>\n",
       "      <td>0.987</td>\n",
       "      <td>0.206</td>\n",
       "      <td>0.726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>tfidf_norm_trim_up</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.988</td>\n",
       "      <td>0.987</td>\n",
       "      <td>0.206</td>\n",
       "      <td>0.724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>tfidf_norm_up</td>\n",
       "      <td>0.073</td>\n",
       "      <td>0.986</td>\n",
       "      <td>0.984</td>\n",
       "      <td>0.204</td>\n",
       "      <td>0.728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>tfidf_norm_trim_up</td>\n",
       "      <td>0.073</td>\n",
       "      <td>0.986</td>\n",
       "      <td>0.984</td>\n",
       "      <td>0.203</td>\n",
       "      <td>0.727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>count_up</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.987</td>\n",
       "      <td>0.985</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>count_up</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.986</td>\n",
       "      <td>0.984</td>\n",
       "      <td>0.198</td>\n",
       "      <td>0.726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>count_up</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.988</td>\n",
       "      <td>0.986</td>\n",
       "      <td>0.198</td>\n",
       "      <td>0.725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>count_up</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.989</td>\n",
       "      <td>0.988</td>\n",
       "      <td>0.196</td>\n",
       "      <td>0.721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>tfidf_norm_up</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.985</td>\n",
       "      <td>0.983</td>\n",
       "      <td>0.195</td>\n",
       "      <td>0.720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>tfidf_norm_trim_up</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.985</td>\n",
       "      <td>0.983</td>\n",
       "      <td>0.195</td>\n",
       "      <td>0.718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>ngram_snow_tfidf</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.234</td>\n",
       "      <td>0.764</td>\n",
       "      <td>0.195</td>\n",
       "      <td>0.703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>count_up</td>\n",
       "      <td>0.073</td>\n",
       "      <td>0.990</td>\n",
       "      <td>0.990</td>\n",
       "      <td>0.193</td>\n",
       "      <td>0.716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>tfidf_norm_trim</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.232</td>\n",
       "      <td>0.763</td>\n",
       "      <td>0.193</td>\n",
       "      <td>0.701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>count_up</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.985</td>\n",
       "      <td>0.983</td>\n",
       "      <td>0.192</td>\n",
       "      <td>0.721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>tfidf_norm</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.232</td>\n",
       "      <td>0.763</td>\n",
       "      <td>0.192</td>\n",
       "      <td>0.700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>count_up</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.992</td>\n",
       "      <td>0.993</td>\n",
       "      <td>0.189</td>\n",
       "      <td>0.710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>tfidf_norm_trim_up</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.984</td>\n",
       "      <td>0.982</td>\n",
       "      <td>0.187</td>\n",
       "      <td>0.708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>count_up</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.985</td>\n",
       "      <td>0.983</td>\n",
       "      <td>0.186</td>\n",
       "      <td>0.714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>tfidf_norm_up</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.984</td>\n",
       "      <td>0.982</td>\n",
       "      <td>0.186</td>\n",
       "      <td>0.709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>count_up</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.994</td>\n",
       "      <td>0.995</td>\n",
       "      <td>0.186</td>\n",
       "      <td>0.704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>ngram_snow_tfidf</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.226</td>\n",
       "      <td>0.759</td>\n",
       "      <td>0.186</td>\n",
       "      <td>0.696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>tfidf_norm</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.223</td>\n",
       "      <td>0.758</td>\n",
       "      <td>0.184</td>\n",
       "      <td>0.694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>tfidf_norm_trim</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.223</td>\n",
       "      <td>0.758</td>\n",
       "      <td>0.184</td>\n",
       "      <td>0.693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>tfidf_norm</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.219</td>\n",
       "      <td>0.755</td>\n",
       "      <td>0.181</td>\n",
       "      <td>0.692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>tfidf_norm_trim</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.219</td>\n",
       "      <td>0.755</td>\n",
       "      <td>0.181</td>\n",
       "      <td>0.692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>ngram_snow_tfidf</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.219</td>\n",
       "      <td>0.755</td>\n",
       "      <td>0.181</td>\n",
       "      <td>0.692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>count_up</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.984</td>\n",
       "      <td>0.982</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>tfidf_norm</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.218</td>\n",
       "      <td>0.755</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>tfidf_norm_trim</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.219</td>\n",
       "      <td>0.755</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>ngram_snow_tfidf</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.219</td>\n",
       "      <td>0.755</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>tfidf_norm</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.218</td>\n",
       "      <td>0.755</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>tfidf_norm_trim</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.218</td>\n",
       "      <td>0.755</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>ngram_snow_tfidf</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.218</td>\n",
       "      <td>0.755</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>ngram_snow_tfidf</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.219</td>\n",
       "      <td>0.756</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>ngram_snow_tfidf</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.219</td>\n",
       "      <td>0.756</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>tfidf_norm_trim_up</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.984</td>\n",
       "      <td>0.981</td>\n",
       "      <td>0.178</td>\n",
       "      <td>0.696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>tfidf_norm_up</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.984</td>\n",
       "      <td>0.981</td>\n",
       "      <td>0.176</td>\n",
       "      <td>0.694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>tfidf_norm_trim_up</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.984</td>\n",
       "      <td>0.981</td>\n",
       "      <td>0.170</td>\n",
       "      <td>0.687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>tfidf_norm_up</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.984</td>\n",
       "      <td>0.981</td>\n",
       "      <td>0.170</td>\n",
       "      <td>0.686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>tfidf_norm_trim_up</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.983</td>\n",
       "      <td>0.981</td>\n",
       "      <td>0.166</td>\n",
       "      <td>0.681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>tfidf_norm_up</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.983</td>\n",
       "      <td>0.981</td>\n",
       "      <td>0.166</td>\n",
       "      <td>0.681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>tfidf_norm_trim_up</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.984</td>\n",
       "      <td>0.981</td>\n",
       "      <td>0.165</td>\n",
       "      <td>0.681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>tfidf_norm_trim_up</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.984</td>\n",
       "      <td>0.981</td>\n",
       "      <td>0.165</td>\n",
       "      <td>0.681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>tfidf_norm_up</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.984</td>\n",
       "      <td>0.981</td>\n",
       "      <td>0.165</td>\n",
       "      <td>0.681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>tfidf_norm_up</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.984</td>\n",
       "      <td>0.981</td>\n",
       "      <td>0.165</td>\n",
       "      <td>0.681</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             data_type  l1_param  ap_train  roc_auc_train  ap_val  roc_auc_val\n",
       "24          tfidf_norm     0.250     0.291          0.795   0.241        0.752\n",
       "34     tfidf_norm_trim     0.250     0.289          0.794   0.239        0.749\n",
       "23          tfidf_norm     0.135     0.280          0.790   0.234        0.745\n",
       "64    ngram_snow_tfidf     0.250     0.274          0.787   0.233        0.744\n",
       "33     tfidf_norm_trim     0.135     0.277          0.788   0.233        0.743\n",
       "0                count     0.200     0.326          0.813   0.231        0.748\n",
       "1                count     0.211     0.329          0.814   0.231        0.748\n",
       "2                count     0.224     0.331          0.815   0.231        0.747\n",
       "3                count     0.236     0.334          0.817   0.230        0.747\n",
       "4                count     0.250     0.337          0.818   0.230        0.747\n",
       "22          tfidf_norm     0.073     0.270          0.784   0.227        0.739\n",
       "32     tfidf_norm_trim     0.073     0.267          0.783   0.225        0.736\n",
       "63    ngram_snow_tfidf     0.135     0.261          0.780   0.222        0.733\n",
       "21          tfidf_norm     0.040     0.259          0.778   0.219        0.728\n",
       "31     tfidf_norm_trim     0.040     0.256          0.777   0.217        0.725\n",
       "62    ngram_snow_tfidf     0.073     0.248          0.773   0.211        0.719\n",
       "53       tfidf_norm_up     0.135     0.987          0.985   0.208        0.730\n",
       "20          tfidf_norm     0.021     0.246          0.771   0.208        0.715\n",
       "30     tfidf_norm_trim     0.021     0.246          0.771   0.208        0.715\n",
       "43  tfidf_norm_trim_up     0.135     0.987          0.985   0.207        0.729\n",
       "54       tfidf_norm_up     0.250     0.988          0.987   0.206        0.726\n",
       "44  tfidf_norm_trim_up     0.250     0.988          0.987   0.206        0.724\n",
       "52       tfidf_norm_up     0.073     0.986          0.984   0.204        0.728\n",
       "42  tfidf_norm_trim_up     0.073     0.986          0.984   0.203        0.727\n",
       "9             count_up     0.012     0.987          0.985   0.200        0.728\n",
       "8             count_up     0.006     0.986          0.984   0.198        0.726\n",
       "10            count_up     0.021     0.988          0.986   0.198        0.725\n",
       "11            count_up     0.040     0.989          0.988   0.196        0.721\n",
       "51       tfidf_norm_up     0.040     0.985          0.983   0.195        0.720\n",
       "41  tfidf_norm_trim_up     0.040     0.985          0.983   0.195        0.718\n",
       "61    ngram_snow_tfidf     0.040     0.234          0.764   0.195        0.703\n",
       "12            count_up     0.073     0.990          0.990   0.193        0.716\n",
       "29     tfidf_norm_trim     0.012     0.232          0.763   0.193        0.701\n",
       "7             count_up     0.003     0.985          0.983   0.192        0.721\n",
       "19          tfidf_norm     0.012     0.232          0.763   0.192        0.700\n",
       "13            count_up     0.135     0.992          0.993   0.189        0.710\n",
       "40  tfidf_norm_trim_up     0.021     0.984          0.982   0.187        0.708\n",
       "6             count_up     0.002     0.985          0.983   0.186        0.714\n",
       "50       tfidf_norm_up     0.021     0.984          0.982   0.186        0.709\n",
       "14            count_up     0.250     0.994          0.995   0.186        0.704\n",
       "60    ngram_snow_tfidf     0.021     0.226          0.759   0.186        0.696\n",
       "18          tfidf_norm     0.006     0.223          0.758   0.184        0.694\n",
       "28     tfidf_norm_trim     0.006     0.223          0.758   0.184        0.693\n",
       "15          tfidf_norm     0.001     0.219          0.755   0.181        0.692\n",
       "25     tfidf_norm_trim     0.001     0.219          0.755   0.181        0.692\n",
       "55    ngram_snow_tfidf     0.001     0.219          0.755   0.181        0.692\n",
       "5             count_up     0.001     0.984          0.982   0.180        0.704\n",
       "16          tfidf_norm     0.002     0.218          0.755   0.180        0.692\n",
       "26     tfidf_norm_trim     0.002     0.219          0.755   0.180        0.692\n",
       "56    ngram_snow_tfidf     0.002     0.219          0.755   0.180        0.692\n",
       "17          tfidf_norm     0.003     0.218          0.755   0.180        0.691\n",
       "27     tfidf_norm_trim     0.003     0.218          0.755   0.180        0.691\n",
       "57    ngram_snow_tfidf     0.003     0.218          0.755   0.180        0.691\n",
       "58    ngram_snow_tfidf     0.006     0.219          0.756   0.180        0.691\n",
       "59    ngram_snow_tfidf     0.012     0.219          0.756   0.180        0.691\n",
       "39  tfidf_norm_trim_up     0.012     0.984          0.981   0.178        0.696\n",
       "49       tfidf_norm_up     0.012     0.984          0.981   0.176        0.694\n",
       "38  tfidf_norm_trim_up     0.006     0.984          0.981   0.170        0.687\n",
       "48       tfidf_norm_up     0.006     0.984          0.981   0.170        0.686\n",
       "35  tfidf_norm_trim_up     0.001     0.983          0.981   0.166        0.681\n",
       "45       tfidf_norm_up     0.001     0.983          0.981   0.166        0.681\n",
       "36  tfidf_norm_trim_up     0.002     0.984          0.981   0.165        0.681\n",
       "37  tfidf_norm_trim_up     0.003     0.984          0.981   0.165        0.681\n",
       "46       tfidf_norm_up     0.002     0.984          0.981   0.165        0.681\n",
       "47       tfidf_norm_up     0.003     0.984          0.981   0.165        0.681"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(master_df.sort_values(by = ['ap_val', 'roc_auc_val'], ascending = False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Script Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count\n",
      "l1: 0.20000000000000004\n",
      "ap_train: 0.11731783213710703, roc_train: 0.5140521525166357, ap_val: 0.10622011439461859, roc_val: 0.5067362345668944\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>l1_param</th>\n",
       "      <th>roc_auc_train</th>\n",
       "      <th>ap_train</th>\n",
       "      <th>roc_auc_val</th>\n",
       "      <th>ap_val</th>\n",
       "      <th>data_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.514</td>\n",
       "      <td>0.117</td>\n",
       "      <td>0.507</td>\n",
       "      <td>0.106</td>\n",
       "      <td>count</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   l1_param  roc_auc_train  ap_train  roc_auc_val  ap_val data_type\n",
       "0       0.2          0.514     0.117        0.507   0.106     count"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_df = l1_reg(x_train_ls[0], y_train_ls[0], x_val_ls[0], y_val_ls[0], params_ls[0], data_type_ls[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aspence\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Penalty: l1\n",
      "Best C: 0.001\n"
     ]
    }
   ],
   "source": [
    "logistic = LogisticRegression()\n",
    "\n",
    "penalty = ['l1']\n",
    "\n",
    "params = params_ls[1][0:1]\n",
    "\n",
    "hyperparameters = dict(C = params, penalty = penalty)\n",
    "\n",
    "clf = GridSearchCV(logistic,hyperparameters, cv=5, verbose=0)\n",
    "\n",
    "best_model = clf.fit(x_train_ls[1], y_train_ls[1])\n",
    "\n",
    "print('Best Penalty:', best_model.best_estimator_.get_params()['penalty'])\n",
    "print('Best C:', best_model.best_estimator_.get_params()['C'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 0)\t1.0\n",
      "  (0, 7501)\t2.0\n",
      "  (0, 19199)\t1.0\n",
      "  (0, 23782)\t3.0\n",
      "  (0, 26888)\t1.0\n",
      "  (0, 32514)\t1.0\n",
      "  (0, 36289)\t1.0\n",
      "  (0, 51188)\t1.0\n",
      "  (0, 59811)\t1.0\n",
      "  (0, 69294)\t1.0\n",
      "  (0, 74251)\t1.0\n",
      "  (0, 81738)\t1.0\n",
      "  (0, 87896)\t1.0\n",
      "  (0, 96868)\t1.0\n",
      "  (0, 98777)\t1.0\n",
      "  (0, 111584)\t1.0\n",
      "  (0, 117126)\t2.0\n",
      "  (0, 118584)\t1.0\n",
      "  (0, 127381)\t1.0\n",
      "  (0, 142073)\t2.0\n",
      "  (0, 145906)\t1.0\n",
      "  (0, 162411)\t2.0\n",
      "  (0, 163118)\t1.0\n",
      "  (0, 167188)\t1.0\n",
      "  (0, 174270)\t1.0\n",
      "  :\t:\n",
      "  (450106, 182748)\t96.0\n",
      "  (450107, 182741)\t110.0\n",
      "  (450107, 182742)\t4.654545454545454\n",
      "  (450107, 182743)\t1.746031746031746\n",
      "  (450107, 182744)\t8851.0\n",
      "  (450107, 182745)\t4.054796068240877\n",
      "  (450107, 182746)\t3.520684168655529\n",
      "  (450107, 182747)\t93.0\n",
      "  (450107, 182748)\t94.6236559139785\n",
      "  (450108, 182741)\t11.0\n",
      "  (450108, 182742)\t1.0\n",
      "  (450108, 182743)\t11.0\n",
      "  (450108, 182744)\t1345.0\n",
      "  (450108, 182745)\t3.2966542750929366\n",
      "  (450108, 182746)\t0.4078229229836264\n",
      "  (450108, 182747)\t292.0\n",
      "  (450108, 182748)\t97.60273972602741\n",
      "  (450109, 182741)\t14.0\n",
      "  (450109, 182742)\t4.0\n",
      "  (450109, 182743)\t14.0\n",
      "  (450109, 182744)\t1635.0\n",
      "  (450109, 182745)\t4.182262996941897\n",
      "  (450109, 182746)\t0.512378564713256\n",
      "  (450109, 182747)\t15.0\n",
      "  (450109, 182748)\t100.0\n"
     ]
    }
   ],
   "source": [
    "print(x_train_ls[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = clf.predict(X=x_train_ls[1])\n",
    "y_val_pred = clf.predict(X= x_val_ls[1]) #predict validation values\n",
    "\n",
    "ap_train = average_precision_score(y_train_ls[1], y_train_pred)\n",
    "roc_auc_train = roc_auc_score(y_train_ls[1], y_train_pred)\n",
    "\n",
    "ap_val = average_precision_score(y_val_ls[1], y_val_pred)\n",
    "roc_auc_val = roc_auc_score(y_val_ls[1], y_val_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9176156880276671 0.9331319010908444 0.10222838995170994 0.5013455717656398\n"
     ]
    }
   ],
   "source": [
    "print(ap_train, roc_auc_train, ap_val, roc_auc_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build baseline logistic regression L1 on word counts\n",
    "clf = LogisticRegression(penalty = 'l1', C = 1.0, solver = 'lbfgs')\n",
    "clf.fit(X = X_trn, y = Y_trn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Do predictions\n",
    "Y_val_pred = clf.predict(X= X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate avg precision score and roc_auc_score on validation set\n",
    "avg_p = average_precision_score(Y_val, Y_val_pred)\n",
    "roc_auc = roc_auc_score(Y_val, Y_val_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(avg_p)\n",
    "print(roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns = ['l1_param', 'roc_auc_train', 'ap_train', 'roc_auc_val', 'ap_val'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.append({'l1_param': 1, 'roc_auc_train': 2,\\\n",
    "                           'ap_train': 3, 'roc_auc_val': 4,'ap_val' : 5}, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    clf = LogisticRegression(penalty = 'l1', solver = 'liblinear')\n",
    "    grid = GridSearchCV(cv = 4, estimator = clf, param_grid = dict(C = l1_params))\n",
    "    grid.fit(x_train, y_train)\n",
    "    print(grid.best_score_)\n",
    "    print(grid.best_estimator_.alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Load datasets\n",
    "# data_loc = r'C:\\Users\\aspence\\Dropbox\\Grad_School\\NYU\\03 - ML\\project\\data'\n",
    "\n",
    "# #Training data\n",
    "# df_train = pd.read_csv(data_loc + r'\\df_train.csv', header=0, index_col=0)\n",
    "# y_train = df_train['label']\n",
    "\n",
    "# x_train = sparse.load_npz(data_loc + r'\\wordcount_train.npz')\n",
    "# x_train = sparse.hstack((x_train, df_train.drop(columns=['label']).values))\n",
    "\n",
    "# #Validation data\n",
    "# df_val = pd.read_csv(data_loc + r'\\df_valid.csv', header=0, index_col=0)\n",
    "# y_val = df_val['label']\n",
    "\n",
    "# x_val = sparse.load_npz(data_loc + r'\\wordcount_valid.npz')\n",
    "# x_val = sparse.hstack((x_val, df_val.drop(columns=['label']).values))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
