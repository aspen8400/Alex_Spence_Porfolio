{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "import geopy.distance as gd\n",
    "import os\n",
    "from pandas import ExcelWriter\n",
    "import numpy as np\n",
    "import gmplot\n",
    "import matplotlib.pyplot as plt \n",
    "from functools import reduce\n",
    "import sqlite3 \n",
    "pd.options.display.max_rows = 40\n",
    "pd.options.display.max_columns = 100\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [12, 4]\n",
    "plt.rcParams['figure.dpi'] = 100 # 200 e.g. is really fine, but slower"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python Analysis Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_df(df, col = 'crash_date', min_year = 2019, lat_col = 'latitude', lon_col = 'longitude', geo = True) :\n",
    "    '''\n",
    "    Performs various cleaning to a dataframe\n",
    "    \n",
    "    inputs:\n",
    "    df (pandas dataframe): dataframe with at minimum crash_date, latitude, and longitude columns\n",
    "    col (string): column to convert to datetime\n",
    "    min_year (int): year to filter dataframe >=\n",
    "    lat_col (string): name of latitude column\n",
    "    lon_col (string): name of longitude column\n",
    "    geo (Bool): if True, drop rows which have nan coordinates\n",
    "    \n",
    "    output:\n",
    "    cleaned df\n",
    "    '''\n",
    "    #Convert all columns to lowercase and replace spaces with _\n",
    "    df.columns= df.columns.str.lower().str.replace(' ', '_')\n",
    "    \n",
    "    #Convert date column to datetime\n",
    "    df[col] = pd.to_datetime(df[col])\n",
    "    \n",
    "    #Filter by min_year\n",
    "    df = df.loc[(df[col].dt.year >= min_year)]\n",
    "    df.reset_index(inplace = True, drop = True)\n",
    "    \n",
    "    if geo :\n",
    "        #Drop any coordinates with na\n",
    "        df.dropna(subset=[lat_col, lon_col], inplace = True)\n",
    "#         df = df.loc[0:500] #Uncomment after finishing code\n",
    "        \n",
    "    return df\n",
    "\n",
    "def clean_df_simple(df, lat_col, lon_col) :\n",
    "    #Convert all columns to lowercase and replace spaces with _\n",
    "    df.columns= df.columns.str.lower().str.replace(' ', '_')\n",
    "\n",
    "def clean_serv_df(serv_df, svi_df) :\n",
    "    '''\n",
    "    Cleans and merges the service df and the servicibility_index df\n",
    "    to be used for Tableau visualization\n",
    "    \n",
    "    Inputs: \n",
    "    serv_df (Pandas dataframe): service dataframe\n",
    "    svi_df (Pandas dataframe): servicibility_index dataframe\n",
    "    \n",
    "    Outputs:\n",
    "    pivot_df (Pandas dataframe): merged dataframe\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    #Calculate Total route length / total stop_count = Bus Stop Spacing (ft.)\n",
    "    serv_df = serv_df.groupby(['Route Type', 'Route']).sum().reset_index()\n",
    "    serv_df['Bus Stop Spacing (ft.)'] = serv_df['Route Length (mi)'] / serv_df['stop_count'] * 5280\n",
    "    \n",
    "    #Join with svi_df\n",
    "    merged_df = pd.merge(serv_df, svi_df, on=['Route'], how = 'outer')\n",
    "    merged_df.sort_values(by = ['Route'], inplace = True)\n",
    "#     display(merged_df.head())\n",
    "    \n",
    "    #Reformat the dataframe\n",
    "    pivot_df = pd.melt(merged_df, id_vars = 'Route', var_name = 'Type', value_name = 'Value')\n",
    "    \n",
    "    #Order by Route\n",
    "    pivot_df.sort_values(by = ['Route'], inplace = True)\n",
    "    pivot_df.reset_index(inplace = True)\n",
    "#     display(pivot_df.head(30))\n",
    "    return pivot_df\n",
    "    \n",
    "def merge_shapefile(data_df, shape_file, crs_string = 'epsg:4269') :\n",
    "    '''\n",
    "    data_df : dataframe with some columns including 'longitude' and 'latitude'\n",
    "    shape_file: .shp shape file gpd\n",
    "    \n",
    "    returns - merged_df which is dataframe consisting of the data from data_df, joined with the shape_file\n",
    "    '''\n",
    "    \n",
    "    #Get lat and long of the points in the data_df\n",
    "    geometry = [Point(xy) for xy in zip(data_df.longitude, data_df.latitude)]\n",
    "    crs = {'init' :crs_string}\n",
    "    #Create geodataframe from the lats and longs\n",
    "    gdf = gpd.GeoDataFrame(data_df, crs=crs, geometry=geometry)\n",
    "#     display(gdf.head())\n",
    "    #Merge the geodataframe with the shape_file\n",
    "    merged_df = gpd.sjoin(gdf, shape_file, how='left', op='within')\n",
    "    \n",
    "    return merged_df\n",
    "\n",
    "def calc_dist(df, start_lat_col = 'latitude', start_lon_col = 'longitude',\\\n",
    "              end_lat = 41.7383652, end_lon = -87.7313064, new_col = 'dist') :\n",
    "    '''\n",
    "    input:\n",
    "        df: dataframe with latitude and longitude columns\n",
    "        start_lat_col: name of latitude column in df (string)\n",
    "        start_lon_col: name of longitude column in df (string)\n",
    "        end_lat: end latitude (i.e. 41.7383652) (float)\n",
    "        end_lon: end longitude (i.e. -87.7313064) (float)\n",
    "        end_lat, end_lon : coordinate to calculate distance from lat/longs given in df\n",
    "        new_col: new column name to store distances in, i.e. 'dist' (string)\n",
    "        \n",
    "    output:\n",
    "        returns nothing, but edits df in place to include new distance column\n",
    "        \n",
    "        '''\n",
    "    df[new_col] = df.apply(\\\n",
    "                          (lambda row: gd.distance((row[start_lat_col], row[start_lon_col]),\\\n",
    "                                                   (end_lat, end_lon)).miles), axis=1)\n",
    "def filter_by_dist(df, start_lat_col = 'Start Lat', start_lon_col = 'Start Long',\\\n",
    "              end_lat = 41.7383652, end_lon = -87.7313064, new_col = 'dist', dist = 0.25) :\n",
    "\n",
    "    '''\n",
    "    input:\n",
    "        df: dataframe with latitude and longitude columns\n",
    "        new_col: new column name to store distances in, i.e. 'dist' (string)\n",
    "        dist: filtering distance in miles (i.e. 0.25)\n",
    "        \n",
    "    output:\n",
    "        returns the df filtered by the specified distance\n",
    "        \n",
    "        '''\n",
    "    cond1 = (df[new_col] <= dist)\n",
    "    df = df.loc[cond1]\n",
    "    return df\n",
    "\n",
    "def add_census_tracts(df) :\n",
    "    '''\n",
    "    Adds census tract populations of the same census tract\n",
    "    df: census_population data with columns 'Census Tract' and 'Population'\n",
    "    \n",
    "    returns df\n",
    "    '''\n",
    "    new_df = df.groupby(['Census Tract']).sum()\n",
    "    new_df.reset_index(inplace = True)\n",
    "    return new_df\n",
    "    \n",
    "def create_lookup_table(df, col1, col2) :\n",
    "    '''\n",
    "    Creates lookup dictionary with col1 as the key and col2 as the value\n",
    "    df: df with col1 and col2\n",
    "    col1: string name of column (assumes col1 type should be float)\n",
    "    col2: string name of another column\n",
    "    \n",
    "    returns dictionary\n",
    "    '''\n",
    "    comm_df = df.loc[:, [col1, col2]]\n",
    "    comm_df[col1] = comm_df[col1].astype(float)\n",
    "    comm_df.set_index(col1, inplace = True)\n",
    "#     display(comm_df.loc[17031700302])\n",
    "#     comm_df.drop_duplicates(inplace = True) Was dropping too much for some reason...\n",
    "#     display(comm_df.loc[17031700302])\n",
    "    comm_dict = comm_df.to_dict()\n",
    "    comm_dict = comm_dict[col2]\n",
    "#     print(comm_dict[17031700302.0])\n",
    "    return comm_dict\n",
    "\n",
    "def gmap_plotter(lats, longs, path, zoom = 15) :\n",
    "    '''\n",
    "    Plots a series of lat and long points on google maps\n",
    "    \n",
    "    Inputs:\n",
    "    lats, longs (pandas series): series values of lats and longs\n",
    "    path (string): path to save gmplot\n",
    "    zoom (int): zoom level for map\n",
    "    \n",
    "    Outputs:\n",
    "    function returns nothing, but a HTML google maps plot is saved to specified path\n",
    "    '''\n",
    "    \n",
    "    #zoom level 0 - widest zoom, >> - narrowest zoom\n",
    "    \n",
    "    #lats are series\n",
    "    lat_start = lats.iloc[int(round(lats.shape[0]/2))]\n",
    "    \n",
    "    #longs are series\n",
    "    long_start = longs.iloc[int(round(longs.shape[0]/2))]\n",
    "    \n",
    "    #starting point of map\n",
    "    gmap = gmplot.GoogleMapPlotter(lat_start, long_start, zoom)\n",
    "    \n",
    "    #Plot all points\n",
    "    gmap.scatter(lats, longs,'#FF0000', \\\n",
    "                              size = 3 , marker = False) \n",
    "    \n",
    "    #Big first two points (green)\n",
    "    gmap.scatter(lats.iloc[0:2], longs.iloc[0:2], '#00ff0d', marker = False, size = 100)\n",
    "    \n",
    "    #Big last two points (red)\n",
    "    gmap.scatter(lats.iloc[-2:], longs.iloc[-2:], '#FF0000', marker = False, size = 100)\n",
    "    \n",
    "    #Plot the entire path\n",
    "    #gmap.plot(lats, longs, 'cornflowerblue', edge_width = 4)\n",
    "    \n",
    "    #Plot to html\n",
    "    gmap.draw(path) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting and Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bar_plot_by_val(df, val, col1, col2):\n",
    "    '''\n",
    "    Inputs:\n",
    "        df: original dataframe to filter from\n",
    "        col1, val: set col1 = val and filter df\n",
    "        col2: bar chart x axis value\n",
    "    \n",
    "    Output:\n",
    "        return: bar plot\n",
    "        \n",
    "    '''\n",
    "    #Filter df col by val\n",
    "#     temp_df = df.groupby(['student_id']).max().reset_index()\n",
    "    temp_df = df.loc[(df[col1] == val), [col2]]\n",
    "    temp_df[col2].value_counts(ascending=True).sort_index(ascending = True)\\\n",
    "    .plot(kind = 'bar')\n",
    "    plt.xlabel(col2)\n",
    "    plt.ylabel('number of _')\n",
    "    plt.title(val)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pysqlite3.connect(path) as connection:\n",
    "    cursor = connection.cursor()\n",
    "    \n",
    "def sql_func(query, cols) :\n",
    "    '''\n",
    "    Inputs:\n",
    "        query: SQL query string\n",
    "               Example:\n",
    "               \n",
    "                    SELECT r.id, s.deg, s.group,\n",
    "                    s.organization, c.course_id, c.course_title,\n",
    "                    c.credits, \n",
    "\n",
    "                    SUM(c.credits) OVER (PARTITION BY r.id) \n",
    "                    ORDER BY r.term_date) as runnning_total_credits,\n",
    "\n",
    "                    SUM(c.credits) OVER (PARTITION BY r.id) \n",
    "                    as total_credits, r.term_date,\n",
    "\n",
    "                    MIN(r.term_date) OVER (PARTITION BY r.id)\n",
    "                    as min_term_date, \n",
    "\n",
    "                    MAX(r.term_date) OVER (PARTITION BY r.id)\n",
    "                    as max_term_date\n",
    "\n",
    "                    FROM (registration r \n",
    "                    LEFT JOIN student s\n",
    "                    ON r.id = s.id) as q1\n",
    "                    LEFT JOIN course c \n",
    "                    ON q1.course_id = c.course_id\n",
    "\n",
    "                    ORDER BY s.organization, r.id, r.term_date\n",
    "               \n",
    "        cols: list of columns to label dataframe\n",
    "    Output:\n",
    "        dataframe of query result\n",
    "        \n",
    "        '''\n",
    "    cursor.execute(query)\n",
    "    df = cursor.fetchall()\n",
    "    df = pd.DataFrame(data = df, columns = cols)\n",
    "    return df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
